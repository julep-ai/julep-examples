{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Julep with Llama 3 8B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "- A VM with an Nvidia L4 or higher GPU.\n",
    "- CUDA 12.2\n",
    "- Docker Compose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Steps to run\n",
    "\n",
    "- Clone the repo from GitHub: https://github.com/julep-ai/julep/\n",
    "- `mv .env.example .env`\n",
    "- Add JWT shared key in `.env`\n",
    "- Add JWT shared key in `scripts/generate_jwt.py`\n",
    "- `docker compose build && docker compose up -d`\n",
    "- Create your API key `python scripts/generate_jwt.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cookbook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### On the dev server\n",
    "\n",
    "`.env`\n",
    "\n",
    "JULEP_API_URL=http://server-ip/api\n",
    "\n",
    "\n",
    "JULEP_API_KEY=api_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from julep import Client\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "api_key = os.environ[\"JULEP_API_KEY\"]\n",
    "base_url = os.environ[\"JULEP_API_URL\"]\n",
    "\n",
    "client = Client(api_key=api_key, base_url=base_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOOLS = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"search_forum\",\n",
    "            \"description\": \"Retrieves a list of posts from a forum for the given search parameters. The search parameters should include the search query and additional parameters such as: category, order, minimum views, and maximum views. The tool will return a list of posts based on the search query and additional parameters. It should be used when the user asks to start monitoring the forum.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The search query to be used to search for posts in the forum.\",\n",
    "                    },\n",
    "                    \"order\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The order in which the posts should be sorted. Possible values are: latest, likes, views, latest_topic.\",\n",
    "                    },\n",
    "                    \"min_views\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The minimum number of views a post should have to be included in the search results.\",\n",
    "                    },\n",
    "                    \"max_views\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The maximum number of views a post should have to be included in the search results.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"query\", \"order\", \"min_views\", \"max_views\", \"category\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"read_post\",\n",
    "            \"description\": \"Retrieves the details of a specific post from the forum. The tool should take the post ID as input and return the details of the post including the content, author, date, and other relevant information. It should be used when the user asks to read a specific post.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"post_id\": {\n",
    "                        \"type\": \"number\",\n",
    "                        \"description\": \"The ID of the post to be read.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"post_id\"],\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = client.agents.create(\n",
    "    name=\"Archy\",\n",
    "    about=\"\",\n",
    "    tools=TOOLS,\n",
    "    model=\"julep-ai/Hermes-2-Theta-Llama-3-8B\",\n",
    "    # model=\"gpt-4o\",\n",
    "    metadata={\"name\": \"Archy\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = client.users.create(\n",
    "    name=\"Anon\",\n",
    "    about=\"A product manager at OpenAI, working with Archy to validate and improve the product\",\n",
    "    metadata={\"name\": \"Anon\"},\n",
    "    docs=[],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open-source LLM caveats.\n",
    "\n",
    "- The following is a template of how the situation prompt **should** look like when using Hermes-Theta-Llama-3.\n",
    "- The `schema`, `tool_call` and `tools` variables should be added in the situation prompt as shown.\n",
    "- It helps to prompt the model that it can call functions.\n",
    "- Following the is the system/situation prompt as suggested by the makers of Hermes-Theta-Llama-3 adapted to Julep's Agents.\n",
    "- When creating a session, **make sure to set `render_templates=True`. Otherwise the agent/LLM will not have access to the tools you define."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"arguments\": {\"title\": \"Arguments\", \"type\": \"object\"},\n",
    "        \"name\": {\"title\": \"Name\", \"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"arguments\", \"name\"],\n",
    "    \"title\": \"FunctionCall\",\n",
    "    \"type\": \"object\",\n",
    "}\n",
    "\n",
    "tool_call = \"\"\"<tool_call>\n",
    "{\"arguments\": <args-dict>, \"name\": <function-name>}\n",
    "</tool_call>\"\"\"\n",
    "\n",
    "tools = \"{{ agent.tools }}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SITUATION_PROMPT = \"\"\"\n",
    "You are a function calling AI agent with self-recursion.\n",
    "You can call only one function at a time and analyse data you get from function response.\n",
    "You are provided with function signatures within <tools></tools> XML tags.\n",
    "You may use agentic frameworks for reasoning and planning to help with user query.\n",
    "Please call a function and wait for function results to be provided to you in the next iteration.\n",
    "Don't make assumptions about what values to plug into function arguments.\n",
    "Once you have called a function, results will be fed back to you within <tool_response></tool_response> XML tags.\n",
    "Don't make assumptions about tool results if <tool_response> XML tags are not present since function hasn't been executed yet.\n",
    "Analyze the data once you get the results and call another function.\n",
    "At each iteration please continue adding the your analysis to previous summary.\n",
    "Your final response should directly answer the user query with an anlysis or summary of the results of function calls.\n",
    "\n",
    "Here are the available tools:\n",
    "<tools> {tools} </tools>\n",
    "Make sure that the json object above with code markdown block is parseable with json.loads() and the XML block with XML ElementTree.\n",
    "\n",
    "Use the following pydantic model json schema for each tool call you will make:\n",
    "{schema}\n",
    "\n",
    "For each function call return a valid json object (using doulbe quotes) with function name and arguments within <tool_call></tool_call> XML tags as follows:\n",
    "{tool_call}\n",
    "\"\"\".format(\n",
    "    tools=tools, schema=schema, tool_call=tool_call\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = client.sessions.create(\n",
    "    agent_id=agent.id,\n",
    "    situation=SITUATION_PROMPT,\n",
    "    metadata={\"agent_id\": agent.id},\n",
    "    render_templates=True,  # set to true when using OSS LLMs!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_msg = \"i wanna search for the common errors openai's assistant api. use defaults\"\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_msg,\n",
    "        \"name\": \"Anon\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.sessions.chat(\n",
    "    session_id=session.id,\n",
    "    messages=messages,\n",
    "    # recall=True,  # bring previous messages to context\n",
    "    # remember=True,  # save this message turn to context\n",
    ")\n",
    "print(response.response[0][0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "tools = json.loads(response.response[0][0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.finish_reason"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
